import SwiftUI
import Combine

import SwiftUI
import Combine

struct ContentView: View {
    @StateObject private var audioToInstrument = AudioToInstrument()
    @State private var isRunning = false

    var body: some View {
        VStack(spacing: 20) {
            Text("üéµ „Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Éê„É≥„Éâ")
                .font(.largeTitle)
                .bold()

            Text("ÁèæÂú®„ÅÆÂë®Ê≥¢Êï∞: \(Int(audioToInstrument.detectedPitch)) Hz")
                .font(.headline)
                .foregroundColor(.blue)

            HStack {
                Button(action: {
                    if isRunning {
                        audioToInstrument.stop()
                    } else {
                        audioToInstrument.start()
                    }
                    isRunning.toggle()
                }) {
                    Text(isRunning ? "ÂÅúÊ≠¢" : "ÈñãÂßã")
                        .font(.title)
                        .frame(width: 120, height: 50)
                        .background(isRunning ? Color.red : Color.green)
                        .foregroundColor(.white)
                        .cornerRadius(10)
                }
            }
        }
        .padding()
    }
}


import AudioKit
import AudioKitUI
import AVFoundation

import AudioKit
import AudioKitUI
import AVFoundation

class AudioAnalyzer: ObservableObject {
    private var engine = AudioEngine()
    private var mic: AudioEngine.InputNode?
    private var tracker: PitchTap!
    private var mixer = Mixer()
    private let smoother = FrequencySmoother()  // „Çπ„É†„Éº„Ç∏„É≥„Ç∞Áî®
    private var synthesizer: SoundSynthesizer

    @Published var detectedPitch: Float = 0.0

    init(synth: SoundSynthesizer) {
        synthesizer = synth

        guard let input = engine.input else {
            fatalError("‚ùå „Éû„Ç§„ÇØÂÖ•Âäõ„ÅåÂèñÂæó„Åß„Åç„Åæ„Åõ„Çì„ÄÇ`NSMicrophoneUsageDescription` „Çí `Info.plist` „Å´ËøΩÂä†„Åó„Åæ„Åó„Åü„ÅãÔºü")
        }
        mic = input
        engine.output = mixer

        // ‚úÖ „Éû„Ç§„ÇØ„ÅÆ„Çµ„É≥„Éó„É´„É¨„Éº„Éà„ÇíÂèñÂæó„ÅóÁµ±‰∏Ä
        let sampleRate = AVAudioSession.sharedInstance().sampleRate
        print("üé§ „Éû„Ç§„ÇØ„ÅÆ„Çµ„É≥„Éó„É´„É¨„Éº„Éà: \(sampleRate) Hz")

        let format = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                   sampleRate: sampleRate,  // ‚úÖ 48000Hz„Å´Áµ±‰∏Ä
                                   channels: 1,
                                   interleaved: false)

        // ‚úÖ `installTap` „ÅÆ„Çµ„É≥„Éó„É´„É¨„Éº„Éà„ÇíÁµ±‰∏Ä
        input.avAudioNode.installTap(onBus: 0, bufferSize: 1024, format: format) { _, _ in }

        // ‚úÖ `PitchTap` „ÅÆ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Çí„Éû„Ç§„ÇØ„Å®Áµ±‰∏Ä
        tracker = PitchTap(input) { pitch, amplitudes in
            DispatchQueue.main.async {
                let detected = pitch.first ?? 0.0
                let amplitude = amplitudes.first ?? 0.0

                if detected > 80 && detected < 1000 && amplitude > 0.01 {
                    let smoothedFreq = self.smoother.smooth(detected)
                    self.detectedPitch = smoothedFreq
                    self.synthesizer.updateFrequency(smoothedFreq)
                    print("üéµ „É™„Ç¢„É´„Çø„Ç§„É†Âë®Ê≥¢Êï∞: \(smoothedFreq) Hz, Èü≥Èáè: \(amplitude)")
                }
            }
        }
    }

    func start() {
        do {
            try engine.start()
            tracker.start()
            print("üé§ „Éû„Ç§„ÇØÂÖ•Âäõ & „Éî„ÉÉ„ÉÅÊ§úÂá∫ÈñãÂßã")
        } catch {
            print("‚ùå AudioEngine „ÅÆËµ∑Âãï„Å´Â§±Êïó: \(error.localizedDescription)")
        }
    }

    func stop() {
        tracker.stop()
        engine.stop()
    }
}

import AudioKit
import SoundpipeAudioKit
import AVFoundation

class SoundSynthesizer: ObservableObject {
    private var engine = AudioEngine()
    private var oscillator: DynamicOscillator

    init() {
        oscillator = DynamicOscillator()
        oscillator.amplitude = 0.3  // Èü≥ÈáèË™øÊï¥
        engine.output = oscillator
    }

    func updateFrequency(_ frequency: Float) {
        DispatchQueue.main.async {
            if frequency > 80 && frequency < 1000 {  // „Éé„Ç§„Ç∫Èô§Âéª
                self.oscillator.frequency = frequency
            }
        }
    }

    func start() {
        do {
            try engine.start()
            oscillator.start()
        } catch {
            print("‚ùå AudioEngine „ÅÆËµ∑Âãï„Å´Â§±Êïó: \(error.localizedDescription)")
        }
    }

    func stop() {
        oscillator.stop()
        engine.stop()
    }
}

class FrequencySmoother {
    private var lastFrequency: Float = 440.0
    private let smoothingFactor: Float = 0.1  // 0.1 „Äú 0.3 „Åè„Çâ„ÅÑ„ÅßË™øÊï¥

    func smooth(_ newFrequency: Float) -> Float {
        lastFrequency = (smoothingFactor * newFrequency) + ((1 - smoothingFactor) * lastFrequency)
        return lastFrequency
    }
}

import AudioKit
import Combine

class AudioToInstrument: ObservableObject {
    let analyzer: AudioAnalyzer
    private let synthesizer: SoundSynthesizer
    private var cancellables = Set<AnyCancellable>()

    @Published var detectedPitch: Float = 0.0

    init() {
        self.synthesizer = SoundSynthesizer()
        self.analyzer = AudioAnalyzer(synth: synthesizer)

        analyzer.$detectedPitch
            .sink { pitch in
                if pitch > 50 {  // ‰Ωé„Åô„Åé„Çã„Éé„Ç§„Ç∫„ÅØÁÑ°Ë¶ñ
                    self.synthesizer.updateFrequency(pitch)
                }
            }
            .store(in: &cancellables)
    }

    func start() {
        analyzer.start()
        synthesizer.start()
    }

    func stop() {
        analyzer.stop()
        synthesizer.stop()
    }
}
